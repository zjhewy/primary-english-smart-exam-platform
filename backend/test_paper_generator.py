#!/usr/bin/env python3
"""
è‡ªåŠ¨ç»„å·ç®—æ³•æµ‹è¯•è„šæœ¬
æµ‹è¯•ç»„å·ç®—æ³•çš„æ ¸å¿ƒé€»è¾‘å’Œæ­£ç¡®æ€§
"""

import sys
import random
from typing import List

class QuestionType:
    """é¢˜ç›®ç±»å‹æšä¸¾"""
    SINGLE_CHOICE = "single_choice"
    LISTENING = "listening"
    READING = "reading"

class Difficulty:
    """éš¾åº¦çº§åˆ«æšä¸¾"""
    EASY = "easy"
    MEDIUM = "medium"
    HARD = "hard"

class Question:
    """é¢˜ç›®æ•°æ®ç±»"""
    def __init__(self, q_id: str, q_type: str, grade: int, unit: int, difficulty: str, score: int):
        self.id = q_id
        self.type = q_type
        self.grade = grade
        self.unit = unit
        self.difficulty = difficulty
        self.score = score

class PaperConfig:
    """ç»„å·é…ç½®ç±»"""
    def __init__(self, grade_range: List[int], unit_range: List[int],
                 total_score: int, question_distribution: dict, difficulty_distribution: dict):
        self.grade_range = grade_range
        self.unit_range = unit_range
        self.total_score = total_score
        self.question_distribution = question_distribution
        self.difficulty_distribution = difficulty_distribution

def generate_test_questions(count: int = 100) -> List[Question]:
    """ç”Ÿæˆæµ‹è¯•é¢˜ç›®"""
    print("ğŸ“ ç”Ÿæˆæµ‹è¯•é¢˜ç›®...")
    questions = []
    types = [QuestionType.SINGLE_CHOICE, QuestionType.LISTENING, QuestionType.READING]
    difficulties = [Difficulty.EASY, Difficulty.MEDIUM, Difficulty.HARD]

    for i in range(count):
        questions.append(Question(
            q_id=f"q_{i:04d}",
            q_type=random.choice(types),
            grade=random.choice([3, 4, 5, 6]),
            unit=random.randint(1, 12),
            difficulty=random.choice(difficulties),
            score=random.choice([2, 3, 5, 10])
        ))

    return questions

def print_statistics(questions: List[Question]):
    """æ‰“å°é¢˜ç›®ç»Ÿè®¡ä¿¡æ¯"""
    print("\nğŸ“Š é¢˜ç›®ç»Ÿè®¡ï¼š")

    type_count = {}
    for q in questions:
        type_count[q.type] = type_count.get(q.type, 0) + 1

    print("   é¢˜å‹åˆ†å¸ƒï¼š")
    for q_type in [QuestionType.SINGLE_CHOICE, QuestionType.LISTENING, QuestionType.READING]:
        count = type_count.get(q_type, 0)
        print(f"   - {q_type:15s}: {count:3d} é“")

    grade_count = {}
    for q in questions:
        grade_count[q.grade] = grade_count.get(q.grade, 0) + 1

    print("\n   å¹´çº§åˆ†å¸ƒï¼š")
    for grade in [3, 4, 5, 6]:
        count = grade_count.get(grade, 0)
        print(f"   - {grade}å¹´çº§: {count:3d} é“")

    diff_count = {}
    for q in questions:
        diff_count[q.difficulty] = diff_count.get(q.difficulty, 0) + 1

    print("\n   éš¾åº¦åˆ†å¸ƒï¼š")
    for diff in [Difficulty.EASY, Difficulty.MEDIUM, Difficulty.HARD]:
        count = diff_count.get(diff, 0)
        print(f"   - {diff:8s}: {count:3d} é“")

def filter_questions(questions: List[Question], config: PaperConfig) -> List[Question]:
    """ç­›é€‰ç¬¦åˆæ¡ä»¶çš„é¢˜ç›®"""
    filtered = []
    for q in questions:
        if q.grade not in config.grade_range:
            continue
        if q.unit < config.unit_range[0] or q.unit > config.unit_range[1]:
            continue
        filtered.append(q)
    return filtered

def generate_paper(config: PaperConfig, available_questions: List[Question]) -> List[Question]:
    """æ¨¡æ‹Ÿç»„å·è¿‡ç¨‹"""
    selected = []
    used_ids = set()

    for q_type, target_score in config.question_distribution.items():
        type_questions = [q for q in available_questions if q.type == q_type]
        current_score = 0

        for _ in range(100):  # æœ€å¤šå°è¯•100æ¬¡
            remaining = target_score - current_score
            if remaining <= 0:
                break

            # é€‰æ‹©éš¾åº¦
            difficulty = random.choices(
                list(config.difficulty_distribution.keys()),
                weights=list(config.difficulty_distribution.values())
            )[0]

            # é€‰æ‹©é¢˜ç›®
            available = [
                q for q in type_questions
                if q.difficulty == difficulty
                and q.id not in used_ids
            ]

            if not available:
                continue

            # æ‰¾æœ€æ¥è¿‘çš„é¢˜ç›®
            best = min(available, key=lambda x: abs(x.score - remaining))
            selected.append(best)
            used_ids.add(best.id)
            current_score += best.score

    return selected

def validate_paper(selected: List[Question], config: PaperConfig) -> dict:
    """éªŒè¯ç”Ÿæˆçš„è¯•å·"""
    total_score = sum(q.score for q in selected)

    score_by_type = {}
    for q in selected:
        score_by_type[q.type] = score_by_type.get(q.type, 0) + q.score

    score_by_diff = {}
    for q in selected:
        score_by_diff[q.difficulty] = score_by_diff.get(q.difficulty, 0) + q.score

    return {
        'total_score': total_score,
        'question_count': len(selected),
        'score_by_type': score_by_type,
        'score_by_diff': score_by_diff
    }

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 60)
    print("ğŸ¯ è‡ªåŠ¨ç»„å·ç®—æ³•æµ‹è¯•")
    print("=" * 60)

    # æ­¥éª¤1ï¼šç”Ÿæˆæµ‹è¯•é¢˜ç›®
    questions = generate_test_questions(100)
    print(f"âœ… æˆåŠŸç”Ÿæˆ {len(questions)} é“æµ‹è¯•é¢˜ç›®")

    # æ­¥éª¤2ï¼šæ˜¾ç¤ºé¢˜ç›®ç»Ÿè®¡
    print_statistics(questions)

    # æ­¥éª¤3ï¼šåˆ›å»ºç»„å·é…ç½®
    print("\nğŸ“‹ åˆ›å»ºç»„å·é…ç½®...")
    config = PaperConfig(
        grade_range=[3, 4],
        unit_range=[1, 6],
        total_score=100,
        question_distribution={
            'single_choice': 60,
            'listening': 30,
            'reading': 10
        },
        difficulty_distribution={
            'easy': 0.3,
            'medium': 0.5,
            'hard': 0.2
        }
    )
    print("âœ… ç»„å·é…ç½®å·²åˆ›å»º")
    print(f"   - å¹´çº§èŒƒå›´: {config.grade_range}")
    print(f"   - å•å…ƒèŒƒå›´: {config.unit_range}")
    print(f"   - æ€»åˆ†: {config.total_score}")
    print(f"   - é¢˜å‹åˆ†å¸ƒ: {config.question_distribution}")
    print(f"   - éš¾åº¦åˆ†å¸ƒ: {config.difficulty_distribution}")

    # æ­¥éª¤4ï¼šç­›é€‰é¢˜ç›®
    print("\nğŸ” ç­›é€‰ç¬¦åˆæ¡ä»¶çš„é¢˜ç›®...")
    filtered = filter_questions(questions, config)
    print(f"âœ… ç­›é€‰å‡º {len(filtered)} é“ç¬¦åˆæ¡ä»¶çš„é¢˜ç›®")

    # æ˜¾ç¤ºç­›é€‰åçš„ç»Ÿè®¡
    print_statistics(filtered)

    # æ­¥éª¤5ï¼šæ‰§è¡Œç»„å·
    print("\nğŸ² æ‰§è¡Œè‡ªåŠ¨ç»„å·...")
    selected = generate_paper(config, filtered)
    print(f"âœ… æˆåŠŸé€‰ä¸­ {len(selected)} é“é¢˜ç›®")

    # æ­¥éª¤6ï¼šéªŒè¯ç»“æœ
    print("\nâœ… éªŒè¯ç»„å·ç»“æœ...")
    result = validate_paper(selected, config)

    total_score = result['total_score']
    deviation = abs(total_score - config.total_score)
    deviation_percent = (deviation / config.total_score) * 100

    print(f"   - å®é™…æ€»åˆ†: {total_score} åˆ†")
    print(f"   - ç›®æ ‡æ€»åˆ†: {config.total_score} åˆ†")
    print(f"   - åå·®: {deviation} åˆ† ({deviation_percent:.1f}%)")
    print(f"   - é¢˜ç›®æ•°é‡: {result['question_count']} é“")

    print("\n   é¢˜å‹åˆ†å¸ƒï¼š")
    for q_type, score in result['score_by_type'].items():
        target = config.question_distribution.get(q_type, 0)
        print(f"   - {q_type:15s}: {score:3d} åˆ† (ç›®æ ‡: {target} åˆ†)")

    print("\n   éš¾åº¦åˆ†å¸ƒï¼š")
    for diff, score in result['score_by_diff'].items():
        target_ratio = config.difficulty_distribution.get(diff, 0) * 100
        actual_ratio = (score / total_score) * 100
        print(f"   - {diff:8s}: {score:3d} åˆ† ({actual_ratio:.1f}%, ç›®æ ‡: {target_ratio:.1f}%)")

    # æ­¥éª¤7ï¼šæ˜¾ç¤ºé€‰ä¸­çš„é¢˜ç›®
    print("\nğŸ“„ é€‰ä¸­çš„é¢˜ç›®åˆ—è¡¨ï¼š")
    for i, q in enumerate(selected, 1):
        print(f"   {i:2d}. [{q.type:12s}] {q.id} - {q.grade}å¹´çº§-{q.unit}å•å…ƒ - {q.difficulty} - {q.score}åˆ†")

    # æ­¥éª¤8ï¼šæœ€ç»ˆéªŒè¯
    print("\n" + "=" * 60)
    print("ğŸ¯ æµ‹è¯•ç»“æœ")
    print("=" * 60)

    if deviation <= config.total_score * 0.1:
        print(f"âœ… ç»„å·æˆåŠŸï¼åå·®åœ¨å…è®¸èŒƒå›´å†…ï¼ˆ10%ï¼‰")
        print(f"   å®é™…å¾—åˆ†: {total_score}/{config.total_score}")
        print(f"   åå·®: {deviation:.1f}%")
        return True
    else:
        print(f"âš ï¸  ç»„å·ç»“æœåå·®è¾ƒå¤§")
        print(f"   å®é™…å¾—åˆ†: {total_score}/{config.total_score}")
        print(f"   åå·®: {deviation:.1f}%")
        return False

if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
